from math import sqrt
from numpy import concatenate
from matplotlib import pyplot
import numpy as np
from pandas import read_csv
from pandas import DataFrame
from pandas import concat
from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import mean_squared_error
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import LSTM
from keras.layers.core import RepeatVector
from keras.models import model_from_yaml
import os
from keras.utils import plot_model

from keras.utils.vis_utils import plot_model

from keras.utils.vis_utils import model_to_dot

#多階層的lstm的autoencoder
#用來壓縮hooklog 輸出hooklog hat然後跟原始的hooklog比對
#取latent做分類用
folder_address = "K:\\aaa"
preoutaddress = "C:\\Users\\Colour\\Desktop\\weight\\"
malware_class_dir ="C:\\Users\\pups1\\PycharmProjects\\project\\Lstmautoencoder_for_malwareapi\\almanahe"
apa = 1000
batch = 10

def gothrougheveryfile(dir): # go through every csv and concat to one csv this part has move to concatallcsv
    i=0
    filenamelist = list()
    for filename in os.listdir(dir): #outside each folder

        wholefilepath = dir +"//" + filename
        filenamelist.append(wholefilepath)

    return filenamelist


def data_to_reconstruction_problem(data,timestep):
    df= DataFrame(data)
    list_concat = list()
    for i in range(timestep-1, -1, -1):
        tempdf = df.shift(i)
        list_concat.append(tempdf)
    data_for_autoencoder=concat(list_concat, axis =1)
    data_for_autoencoder.dropna(inplace = True)
    return data_for_autoencoder


def data_to_reconstruction_problem(data,timestep):
    df= DataFrame(data)
    list_concat = list()
    for i in range(timestep-1, -1, -1):
        tempdf = df.shift(i)
        list_concat.append(tempdf)
    data_for_autoencoder=concat(list_concat, axis =1)
    data_for_autoencoder.dropna(inplace = True)
    return data_for_autoencoder
    
def out_put_core(writting_list, outaddress, filename):
    thefile = open(outaddress+"\\"+filename+".txt", 'w')
    for item in writting_list:
        thefile.write("%s\n" % item)

'''  
for folder in os.listdir(folder_address):
    if folder.endswith('.py') or folder.endswith('.txt'):
        continue
    if not os.path.exists(preoutaddress+folder):
        os.makedirs(preoutaddress+folder)
    file_address = folder_address + "\\" + folder
    outputaddress = preoutaddress + folder
    for file in os.listdir(file_address):
    '''
############################################################# tab 2

#file_name = file_address + "\\" + file
#file_name = "e103de89e5320990d334bde4e8def5b294163f2c46702286812d7ece8ffdef9a_3216.csv"

filepathlist = gothrougheveryfile(malware_class_dir)
n_apis = 16
n_features = 34
for i in range(0,len(filepathlist)):
    dataset = read_csv(filepathlist[i], header=None, index_col=None)
    values = dataset.values
    reframed = data_to_reconstruction_problem(values, n_apis)
    reframed = reframed.astype('float32')
    scaler = MinMaxScaler(feature_range=(0, 1))
    scaled = scaler.fit_transform(reframed)
    #print ("deal with: "+file_name+" in folder: "+folder+" shape: "+str(dfscaled.shape))
    dfscaled = DataFrame(scaled)
    train_X = dfscaled.values
    train_X = train_X.reshape((train_X.shape[0], n_apis, n_features))
    sample_number = train_X.shape[0]
    model = Sequential()
    timesstep16 = n_apis
    timesstep8 = int(n_apis/2)
    timesstep4 = int(n_apis/4)
    #model.add(LSTM(34, input_shape=(train_X.shape[1], train_X.shape[2]), return_sequences=False))

    # model layer
    model.add(LSTM(n_features, input_shape=(n_apis, train_X.shape[2]), return_sequences=True))

    model.add(LSTM(timesstep16, return_sequences=True))

    model.add(LSTM(timesstep8, return_sequences=True))

    model.add(LSTM(timesstep16, return_sequences=True))

    model.add(LSTM(n_features, return_sequences=True))
    model.compile(loss='mse', optimizer='adam')
    # model layer end
    history = model.fit(train_X, train_X, epochs=apa, batch_size=batch, shuffle=False) # train
    #plot_model(model, to_file='model.png')
    #SVG(model_to_dot(model).create(prog='dot', format='svg'))
    #############################################################fuck

    pyplot.plot(history.history['loss'], label='train')
    pyplot.legend()
    #pyplot.show()

    lossepoch = "{}.png".format(os.path.basename(filepathlist[i]))
    pyplot.savefig(lossepoch)
    pyplot.gcf().clear()

    yhat = model.predict(train_X)
    yhat = yhat.reshape(yhat.shape[0],n_apis *n_features)
    yhat = scaler.inverse_transform(yhat)
    df2 = DataFrame(yhat)
    df2.to_csv("yhat_orig_value.csv")

    #############################################################fuck

    ############################################################# tab 2 end

            ##############################################################
    '''
            model2 = Sequential()
            model2.add(LSTM(34, input_shape=(train_X.shape[1], train_X.shape[2]), return_sequences=False, weights=model.layers[0].get_weights()))
            activations = model2.predict(train_X)
            out_put_core(activations.tolist(), outputaddress, file[:file.find(".")])
            yhat = model.predict(train_X)
            yhat = yhat.reshape((n_apis, n_features))
            yhat = scaler.inverse_transform(yhat)
    '''
            ##############################################################
